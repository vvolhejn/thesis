{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using the alternative SPICE pitch detector instead of CREPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "\n",
    "model = hub.load(\"https://tfhub.dev/google/spice/2\")\n",
    "model1 = hub.load(\"https://tfhub.dev/google/spice/1\")\n",
    "\n",
    "# A single wave, 128 samples (8ms at 16kHz) long.\n",
    "wave = np.array(np.sin(np.linspace(-np.pi, np.pi, 128)), dtype=np.float32)\n",
    "\n",
    "# 16 such waves (2048 samples).\n",
    "waves = np.tile(wave, 16)\n",
    "plt.plot(waves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run model. One would use real singing as input, here we use the above\n",
    "# waveform for testing.\n",
    "input = tf.constant(waves)\n",
    "output = model.signatures[\"serving_default\"](input)\n",
    "pitches = output[\"pitch\"]\n",
    "some_pitch = pitches[2]\n",
    "\n",
    "def output2hz(pitch_output):\n",
    "  # Calibration constants\n",
    "  PT_OFFSET = 25.58\n",
    "  PT_SLOPE = 63.07\n",
    "  FMIN = 10.0;\n",
    "  BINS_PER_OCTAVE = 12.0;\n",
    "  cqt_bin = pitch_output * PT_SLOPE + PT_OFFSET;\n",
    "  return FMIN * 2.0 ** (1.0 * cqt_bin / BINS_PER_OCTAVE)\n",
    "\n",
    "# Should be ~ 125 hz\n",
    "print(output2hz(some_pitch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddsp.colab.colab_utils import (audio_bytes_to_np)\n",
    "sample_rate = 16000\n",
    "\n",
    "input_f = open(\"../data/audio/violin/II. Double.mp3\", \"rb\")\n",
    "wav_bytes = input_f.read()\n",
    "audio = audio_bytes_to_np(wav_bytes)\n",
    "audio = audio[:sample_rate * 4]\n",
    "\n",
    "# if len(audio.shape) == 1:\n",
    "#     audio = audio[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codetiming import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer():\n",
    "  crepe_f0_hz, crepe_f0_confidence = ddsp.spectral_ops.compute_f0(\n",
    "    audio,\n",
    "    frame_rate=32,\n",
    "    crepe_model=\"tiny\",\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crepe\n",
    "\n",
    "with Timer():\n",
    "  # Compute f0 with crepe.\n",
    "  _, f0_hz, f0_confidence, _ = crepe.predict(\n",
    "      audio,\n",
    "      sr=sample_rate,\n",
    "      viterbi=True,\n",
    "      step_size=32,\n",
    "      center=False,\n",
    "      model_capacity=\"tiny\",\n",
    "      verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer():\n",
    "  input = tf.constant(audio)\n",
    "  output = model.signatures[\"serving_default\"](input)\n",
    "  pitches = output[\"pitch\"]\n",
    "  #some_pitch = pitches[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer():\n",
    "  input = tf.constant(audio)\n",
    "  output1 = model1.signatures[\"serving_default\"](input)\n",
    "  pitches1 = output1[\"pitch\"]\n",
    "  #some_pitch = pitches[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(crepe_f0_hz)\n",
    "\n",
    "plt.plot(output2hz(output[\"pitch\"]))\n",
    "\n",
    "plt.plot(output2hz(output1[\"pitch\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crepe_f0_hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"pitch\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

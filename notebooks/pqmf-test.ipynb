{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing/debugging PQMF\n",
    "\n",
    "## Warning: outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from thesis import pqmf\n",
    "from ddsp.colab.colab_utils import (\n",
    "    auto_tune, get_tuning_factor, download,\n",
    "    play, record, specplot, upload, audio_bytes_to_np,\n",
    "    DEFAULT_SAMPLE_RATE)\n",
    "import numpy as np\n",
    "import IPython\n",
    "import einops\n",
    "import gin\n",
    "gin.enter_interactive_mode()\n",
    "\n",
    "def play_audio(audio):\n",
    "    audio = np.array(audio)\n",
    "    audio = np.squeeze(audio)\n",
    "    IPython.display.display(IPython.display.Audio(audio, rate=16000))\n",
    "\n",
    "from ddsp.losses import SpectralLoss\n",
    "\n",
    "def get_loss(target_audio, audio):\n",
    "    loss_class = SpectralLoss()\n",
    "    loss = loss_class(tf.convert_to_tensor(target_audio), tf.convert_to_tensor(audio))\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "bands = 8\n",
    "attenuation = 100\n",
    "\n",
    "input_f = open(\"../data/audio/violin/II. Double.mp3\", \"rb\")\n",
    "wav_bytes = input_f.read()\n",
    "audio = audio_bytes_to_np(wav_bytes)\n",
    "audio = audio[:sample_rate * 10]\n",
    "audio_np = audio.copy()\n",
    "\n",
    "if len(audio.shape) == 1:\n",
    "    audio = audio[np.newaxis, :, np.newaxis]\n",
    "\n",
    "audio_tf = tf.convert_to_tensor(audio)\n",
    "audio_torch = torch.Tensor(audio_np).reshape((1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(audio[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p = pqmf.PQMFBank(attenuation=100, n_bands=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p.hk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "z = p.analysis(audio_tf)\n",
    "\n",
    "y = p.synthesis(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(y[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from thesis import pqmf_rave\n",
    "pr = pqmf_rave.PQMF(100, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pr.hk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mean_distance(a, b):\n",
    "    a = np.array(a).squeeze()\n",
    "    b = np.array(b).squeeze()\n",
    "\n",
    "    if a.shape[0] < 50:\n",
    "        a = a.swapaxes(0, 1)\n",
    "\n",
    "    if b.shape[0] < 50:\n",
    "        b = b.swapaxes(0, 1)\n",
    "\n",
    "    abs_distance = np.abs(a - b).mean()\n",
    "    rel_distance = (np.abs(a - b) / (np.abs(a) + np.abs(b) + 1e-9)).mean()\n",
    "    print(abs_distance, rel_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p.hk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hk_for_torch = torch.Tensor(np.array(einops.rearrange(p.hk, \"t 1 m -> m t\")))\n",
    "z_torch_fast = pqmf_rave.polyphase_forward(audio_torch, hk_for_torch)\n",
    "z_torch_fast = pqmf_rave.reverse_half(z_torch_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "z_torch = pqmf_rave.classic_forward(audio_torch, hk_for_torch)\n",
    "z_torch = pqmf_rave.reverse_half(z_torch)\n",
    "z_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample to hear what it sounds like\n",
    "\n",
    "from thesis.util import resample\n",
    "\n",
    "def preview_decomposed(z):\n",
    "    z2 = resample(z, z.shape[1] * 8)\n",
    "\n",
    "    for i in range(3):\n",
    "        play_audio(z2[0,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def polyphase_forward(x, hk):\n",
    "    \"\"\"\n",
    "    Polyphase implementation of the analysis process (fast)\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: torch.Tensor\n",
    "        signal to analyse ( B x T x 1 )\n",
    "\n",
    "    hk: torch.Tensor\n",
    "        filter bank ( T x 1 x M )\n",
    "    \"\"\"\n",
    "    x = einops.rearrange(x, \"b (t m) c -> b t (c m)\", m=hk.shape[-1])\n",
    "    # if rearrange_filter:\n",
    "    # hk = einops.rearrange(hk, \"c (t m) -> c m t\", m=hk.shape[0])\n",
    "\n",
    "    hk = einops.rearrange(hk, \"(t m) 1 c -> t m c\", m=hk.shape[-1])\n",
    "    # print(x.shape)\n",
    "    # print(hk.shape)\n",
    "    # x = nn.functional.conv1d(x, hk, padding=hk.shape[-1] // 2)[..., :-1]\n",
    "    #\n",
    "    # # shape of x: [batch, in_width, in_channels]\n",
    "    # # shape of hk: [filter_width, in_channels, out_channels]\n",
    "    x = tf.nn.conv1d(x, hk, stride=1, padding=\"SAME\")\n",
    "\n",
    "    # x = pqmf.reverse_half(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "zpoly = polyphase_forward(audio_tf, p.hk)\n",
    "print(zpoly.shape)\n",
    "\n",
    "mean_distance(zpoly, z)\n",
    "mean_distance(zpoly, z_torch_fast)\n",
    "mean_distance(z_torch, z_torch_fast)\n",
    "mean_distance(z, z_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def polyphase_inverse(x, hk):\n",
    "    \"\"\"\n",
    "    Polyphase implementation of the synthesis process (fast)\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: torch.Tensor\n",
    "        signal to synthesize from\n",
    "        torch: ( B x 1 x T )\n",
    "        us: B x T x 1\n",
    "\n",
    "    hk: torch.Tensor\n",
    "        filter bank\n",
    "        torch: ( M x T )\n",
    "        us: T x 1 x M\n",
    "    \"\"\"\n",
    "\n",
    "    m = hk.shape[-1]\n",
    "\n",
    "    hk = tf.reverse(hk, [0])\n",
    "\n",
    "    hk = einops.rearrange(hk, \"(t m) 1 c -> t c m\", m=m)\n",
    "\n",
    "    #pad = hk.shape[-1] // 2 + 1\n",
    "    #x = nn.functional.conv1d(x, hk, padding=int(pad))[..., :-1] * m\n",
    "\n",
    "    x = tf.nn.conv1d(x, hk, stride=1, padding=\"SAME\")\n",
    "\n",
    "    x = tf.reverse(x, [1])\n",
    "    x = einops.rearrange(x, \"b t (c m) -> b (t m) c\", m=m)\n",
    "    x = tf.reverse(x, [1])\n",
    "\n",
    "    # x = einops.rearrange(x, \"b t (c m) -> b (t m) c\", m=m)\n",
    "\n",
    "    # x = x[..., 2 * hk.shape[1] :]\n",
    "    return x\n",
    "\n",
    "ypoly = polyphase_inverse(zpoly, p.hk)\n",
    "ypoly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(ypoly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "\n",
    "zpoly = polyphase_forward(audio_tf, p.hk)\n",
    "ypoly = polyphase_inverse(zpoly, p.hk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -n 100\n",
    "\n",
    "zold = p.analysis(audio_tf)\n",
    "yold = p.synthesis(zold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mean_distance(zpoly, zold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import einops\n",
    "import tensorflow as tf\n",
    "from ddsp.losses import SpectralLoss\n",
    "from ddsp.colab.colab_utils import audio_bytes_to_np\n",
    "\n",
    "from thesis.pqmf import PQMFBank\n",
    "\n",
    "\n",
    "def get_loss(target_audio, audio):\n",
    "    loss_class = SpectralLoss()\n",
    "    loss = loss_class(tf.convert_to_tensor(target_audio), tf.convert_to_tensor(audio))\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def get_audio_fixture():\n",
    "    input_f = open(\n",
    "        os.path.join(\"../fixtures/violin_1s.wav\"), \"rb\"\n",
    "    )\n",
    "    wav_bytes = input_f.read()\n",
    "    audio = audio_bytes_to_np(wav_bytes)\n",
    "    return audio\n",
    "\n",
    "\n",
    "audio = get_audio_fixture()\n",
    "audio = tf.convert_to_tensor(audio)\n",
    "\n",
    "# Split into two halves to have a batch size of more than 1\n",
    "batch_size = 2\n",
    "audio = einops.rearrange(audio, \"(b t) -> b t 1\", b=batch_size)\n",
    "n_samples = audio.shape[1]\n",
    "\n",
    "bands = 4\n",
    "attenuation = 100\n",
    "\n",
    "pqmf = PQMFBank(attenuation=attenuation, n_bands=bands)\n",
    "\n",
    "analyzed = pqmf.analysis(audio)\n",
    "# self.assertEqual(\n",
    "#     analyzed.shape.as_list(), [batch_size, n_samples // bands, bands]\n",
    "# )\n",
    "\n",
    "synthesized = pqmf.synthesis(analyzed)\n",
    "# self.assertEqual(synthesized.shape.as_list(), [batch_size, n_samples, 1])\n",
    "\n",
    "# The reconstructed audio should be close enough to the original.\n",
    "# The actual loss value should be <=0.1, so the threshold 1.0 is lenient.\n",
    "print(get_loss(audio, synthesized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "specplot(audio[1,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "specplot(synthesized[1,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(audio[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(synthesized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preview_decomposed(zpoly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preview_decomposed(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preview_decomposed(np.array(einops.rearrange(z_torch_fast, \"1 c t -> 1 t c\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = p1.synthesis(temp)\n",
    "rec1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(rec1)\n",
    "get_loss(audio_tf1, rec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = np.array(temp0).swapaxes(1, 2)\n",
    "t1 = np.array(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((t0 - t1) ** 2).mean())\n",
    "print(((t0 - t1) ** 2).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((np.array(p1.hk).squeeze().T - np.array(p0.hk)) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0.hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec2 = p1.synthesis(t0)\n",
    "print(rec2.shape)\n",
    "play_audio(rec2)\n",
    "get_loss(audio_tf1, rec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec3 = p0.inverse(torch.Tensor(t1.swapaxes(1, 2)))\n",
    "play_audio(rec3)\n",
    "get_loss(audio_tf1, rec3.swapaxes(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(30)\n",
    "x[::5] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t0\n",
    "x1 = tf.nn.conv1d_transpose(\n",
    "    x,\n",
    "    p1.updown_filter * p1.n_band,\n",
    "    strides=p1.n_band,\n",
    "    output_shape=(\n",
    "        tf.shape(x)[0],\n",
    "        tf.shape(x)[1] * p1.n_band,\n",
    "        p1.n_band,\n",
    "    ),\n",
    ")\n",
    "\n",
    "x1_torch = torch.Tensor(np.array(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk = p0.hk.flip(-1)\n",
    "y = nn.functional.conv1d(\n",
    "        x1_torch,\n",
    "        p0.hk.flip(-1).unsqueeze(0),\n",
    "        padding=hk.shape[-1] // 2,\n",
    "    )[..., 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

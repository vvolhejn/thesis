{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from thesis import pqmf\n",
    "from ddsp.colab.colab_utils import (\n",
    "    auto_tune, get_tuning_factor, download,\n",
    "    play, record, specplot, upload, audio_bytes_to_np,\n",
    "    DEFAULT_SAMPLE_RATE)\n",
    "import numpy as np\n",
    "import IPython\n",
    "\n",
    "def play_audio(audio):\n",
    "    audio = np.array(audio)\n",
    "    audio = np.squeeze(audio)\n",
    "    IPython.display.display(IPython.display.Audio(audio, rate=16000))\n",
    "\n",
    "from ddsp.losses import SpectralLoss\n",
    "\n",
    "def get_loss(target_audio, audio):\n",
    "    loss_class = SpectralLoss()\n",
    "    loss = loss_class(tf.convert_to_tensor(target_audio), tf.convert_to_tensor(audio))\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "bands = 8\n",
    "attenuation = 100\n",
    "\n",
    "input_f = open(\"../data/audio/violin/II. Double.mp3\", \"rb\")\n",
    "wav_bytes = input_f.read()\n",
    "audio = audio_bytes_to_np(wav_bytes)\n",
    "audio = audio[:sample_rate * 10]\n",
    "audio_np = audio.copy()\n",
    "\n",
    "if len(audio.shape) == 1:\n",
    "    audio = audio[np.newaxis, :, np.newaxis]\n",
    "\n",
    "audio_tf = tf.convert_to_tensor(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(audio[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p = pqmf.PQMF(pqmf.MultiBandMelGANGeneratorConfig(subbands=8, beta=9, cutoff_ratio=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.synthesis_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -n100\n",
    "# Analysis\n",
    "a = p.analysis(audio_tf)\n",
    "# print(\"Analyzed to\", a.shape)\n",
    "\n",
    "rec_tf = p.synthesis(a)\n",
    "# print(\"Synthesized to\", rec_tf.shape)\n",
    "\n",
    "# play_audio(rec_tf[0,:,0])\n",
    "# get_loss(audio_tf[:,:,0], rec_tf[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Upsample to hear what it sounds like\n",
    "\n",
    "from thesis.newt import resample\n",
    "\n",
    "a2 = resample(a, a.shape[1] * 8)\n",
    "\n",
    "a2.shape\n",
    "\n",
    "for i in range(8):\n",
    "    IPython.display.display(IPython.display.Audio(0.5 * a2[:,:sample_rate*10,i], rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "specplot(audio[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Show spectrograms to visualize\n",
    "for i in range(8):\n",
    "    specplot(a2[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_loss(audio_torch[:,:,0], rec_torch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IPython.display.display(IPython.display.Audio(reconstruction[0,:,0], rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(p.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    plt.plot(p.hk[i][64:-64])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from thesis import pqmf0\n",
    "\n",
    "audio_torch = torch.Tensor(audio_np).reshape((1, 1, -1))\n",
    "\n",
    "p0 = pqmf0.PQMF(attenuation=attenuation, n_band=bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "temp = p0.forward(audio_torch)\n",
    "print(\"Analyzed to\", temp.shape)\n",
    "rec_torch = p0.inverse(temp)\n",
    "# print(\"Synthesized to\", rec_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample to hear what it sounds like\n",
    "\n",
    "from thesis.newt import resample\n",
    "\n",
    "a2 = resample(temp.swapaxes(1, 2), temp.shape[2] * 8)\n",
    "\n",
    "print(a2.shape)\n",
    "\n",
    "for i in range(8):\n",
    "    play_audio(a2[:,:sample_rate*3, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0 = p0.forward(audio_torch)\n",
    "print(\"Analyzed to\", temp0.shape)\n",
    "rec_torch = p0.inverse(temp0)\n",
    "print(\"Synthesized to\", rec_torch.shape)\n",
    "\n",
    "play_audio(rec_torch)\n",
    "\n",
    "get_loss(audio_torch[0], rec_torch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0.hk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom PQMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis import pqmf1\n",
    "\n",
    "# audio_torch = torch.Tensor(audio_np).reshape((1, 1, -1))\n",
    "p1 = pqmf1.PQMF(attenuation=attenuation, n_band=bands, polyphase=False)\n",
    "\n",
    "audio_tf1 = tf.convert_to_tensor(audio_np)\n",
    "audio_tf1 = audio_tf1.reshape((1, -1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = p1.analysis(audio_tf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample to hear what it sounds like\n",
    "\n",
    "from thesis.newt import resample\n",
    "\n",
    "a2 = resample(temp, temp.shape[1] * 8)\n",
    "\n",
    "print(a2.shape)\n",
    "\n",
    "for i in range(8):\n",
    "    play_audio(a2[:,:sample_rate*8,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.synthesis(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

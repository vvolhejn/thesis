{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing/debugging PQMF\n",
    "\n",
    "## Warning: outdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from thesis import pqmf\n",
    "from ddsp.colab.colab_utils import (\n",
    "    auto_tune, get_tuning_factor, download,\n",
    "    play, record, specplot, upload, audio_bytes_to_np,\n",
    "    DEFAULT_SAMPLE_RATE)\n",
    "import numpy as np\n",
    "import IPython\n",
    "\n",
    "def play_audio(audio):\n",
    "    audio = np.array(audio)\n",
    "    audio = np.squeeze(audio)\n",
    "    IPython.display.display(IPython.display.Audio(audio, rate=16000))\n",
    "\n",
    "from ddsp.losses import SpectralLoss\n",
    "\n",
    "def get_loss(target_audio, audio):\n",
    "    loss_class = SpectralLoss()\n",
    "    loss = loss_class(tf.convert_to_tensor(target_audio), tf.convert_to_tensor(audio))\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "bands = 8\n",
    "attenuation = 100\n",
    "\n",
    "input_f = open(\"../data/audio/violin/II. Double.mp3\", \"rb\")\n",
    "wav_bytes = input_f.read()\n",
    "audio = audio_bytes_to_np(wav_bytes)\n",
    "audio = audio[:sample_rate * 10]\n",
    "audio_np = audio.copy()\n",
    "\n",
    "if len(audio.shape) == 1:\n",
    "    audio = audio[np.newaxis, :, np.newaxis]\n",
    "\n",
    "audio_tf = tf.convert_to_tensor(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(audio[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p = pqmf.PQMF(pqmf.MultiBandMelGANGeneratorConfig(subbands=8, beta=9, cutoff_ratio=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.synthesis_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%timeit -n100\n",
    "# Analysis\n",
    "a = p.analysis(audio_tf)\n",
    "# print(\"Analyzed to\", a.shape)\n",
    "\n",
    "rec_tf = p.synthesis(a)\n",
    "# print(\"Synthesized to\", rec_tf.shape)\n",
    "\n",
    "# play_audio(rec_tf[0,:,0])\n",
    "# get_loss(audio_tf[:,:,0], rec_tf[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Upsample to hear what it sounds like\n",
    "\n",
    "from thesis.newt import resample\n",
    "\n",
    "a2 = resample(a, a.shape[1] * 8)\n",
    "\n",
    "a2.shape\n",
    "\n",
    "for i in range(8):\n",
    "    IPython.display.display(IPython.display.Audio(0.5 * a2[:,:sample_rate*10,i], rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "specplot(audio[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Show spectrograms to visualize\n",
    "for i in range(8):\n",
    "    specplot(a2[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from thesis import pqmf0\n",
    "\n",
    "audio_torch = torch.Tensor(audio_np).reshape((1, 1, -1))\n",
    "\n",
    "p0 = pqmf0.PQMF(attenuation=attenuation, n_band=bands, polyphase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "temp0 = p0.forward(audio_torch)\n",
    "print(\"Analyzed to\", temp0.shape)\n",
    "rec0 = p0.inverse(temp0)\n",
    "# print(\"Synthesized to\", rec_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample to hear what it sounds like\n",
    "\n",
    "from thesis.newt import resample\n",
    "\n",
    "a2 = resample(temp0.swapaxes(1, 2), temp0.shape[2] * 8)\n",
    "\n",
    "print(a2.shape)\n",
    "\n",
    "for i in range(8):\n",
    "    play_audio(a2[:,:sample_rate*3, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0 = p0.forward(audio_torch)\n",
    "print(\"Analyzed to\", temp0.shape)\n",
    "rec_torch = p0.inverse(temp0)\n",
    "print(\"Synthesized to\", rec_torch.shape)\n",
    "\n",
    "play_audio(rec_torch)\n",
    "\n",
    "get_loss(audio_torch[0], rec_torch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom PQMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis import pqmf1\n",
    "\n",
    "# audio_torch = torch.Tensor(audio_np).reshape((1, 1, -1))\n",
    "p1 = pqmf1.PQMF(attenuation=attenuation, n_band=bands)\n",
    "\n",
    "audio_tf1 = tf.convert_to_tensor(audio_np)\n",
    "audio_tf1 = audio_tf1.reshape((1, -1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.convert_to_tensor(audio_np)\n",
    "print(x.shape)\n",
    "\n",
    "import einops\n",
    "x = einops.rearrange(x, \"(b t) -> b t 1\", b=2)\n",
    "\n",
    "play_audio(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "audio_tf1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = p1.analysis(audio_tf1)\n",
    "\n",
    "temp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample to hear what it sounds like\n",
    "\n",
    "from thesis.newt import resample\n",
    "\n",
    "a2 = resample(temp, temp.shape[1] * 8)\n",
    "\n",
    "print(a2.shape)\n",
    "\n",
    "for i in range(8):\n",
    "    play_audio(a2[:,:sample_rate*8,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = p1.synthesis(temp)\n",
    "rec1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(rec1)\n",
    "get_loss(audio_tf1, rec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = np.array(temp0).swapaxes(1, 2)\n",
    "t1 = np.array(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(((t0 - t1) ** 2).mean())\n",
    "print(((t0 - t1) ** 2).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((np.array(p1.hk).squeeze().T - np.array(p0.hk)) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0.hk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec2 = p1.synthesis(t0)\n",
    "print(rec2.shape)\n",
    "play_audio(rec2)\n",
    "get_loss(audio_tf1, rec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec3 = p0.inverse(torch.Tensor(t1.swapaxes(1, 2)))\n",
    "play_audio(rec3)\n",
    "get_loss(audio_tf1, rec3.swapaxes(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(30)\n",
    "x[::5] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t0\n",
    "x1 = tf.nn.conv1d_transpose(\n",
    "    x,\n",
    "    p1.updown_filter * p1.n_band,\n",
    "    strides=p1.n_band,\n",
    "    output_shape=(\n",
    "        tf.shape(x)[0],\n",
    "        tf.shape(x)[1] * p1.n_band,\n",
    "        p1.n_band,\n",
    "    ),\n",
    ")\n",
    "\n",
    "x1_torch = torch.Tensor(np.array(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk = p0.hk.flip(-1)\n",
    "y = nn.functional.conv1d(\n",
    "        x1_torch,\n",
    "        p0.hk.flip(-1).unsqueeze(0),\n",
    "        padding=hk.shape[-1] // 2,\n",
    "    )[..., 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

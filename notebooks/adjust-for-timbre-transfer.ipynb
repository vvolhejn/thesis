{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016a59c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import thesis.rave\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import crepe\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "from ddsp.colab.colab_utils import (\n",
    "    auto_tune, get_tuning_factor, download,\n",
    "    play, record, specplot, upload, audio_bytes_to_np,\n",
    "    DEFAULT_SAMPLE_RATE)\n",
    "from ddsp.training.postprocessing import (\n",
    "    detect_notes, fit_quantile_transform\n",
    ")\n",
    "import gin\n",
    "# from google.colab import files\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import tensorflow.compat.v2 as tf\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import einops\n",
    "\n",
    "# Helper Functions\n",
    "# sample_rate = DEFAULT_SAMPLE_RATE  # 16000\n",
    "sample_rate = 16000\n",
    "\n",
    "def play_audio(audio):\n",
    "    audio = np.array(audio)\n",
    "    audio = np.squeeze(audio)\n",
    "    IPython.display.display(IPython.display.Audio(audio, rate=16000))\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21435309",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_f = open(\"../data/audio/violin/II. Double.mp3\", \"rb\")\n",
    "# input_f = open(\"../data/audio/violin/III. Corrente.mp3\", \"rb\")\n",
    "# input_f = open(\"../data/audio/flute/3 Fantaisies for Solo Flute, Op. 38 - Fantaisie no. 1.mp3\", \"rb\")\n",
    "wav_bytes = input_f.read()\n",
    "audio = audio_bytes_to_np(wav_bytes)\n",
    "audio = audio[:sample_rate * 10]\n",
    "\n",
    "if len(audio.shape) == 1:\n",
    "    audio = audio[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb49c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "specplot(audio)\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "IPython.display.Audio(audio, rate=DEFAULT_SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac550b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "# Setup the session.\n",
    "ddsp.spectral_ops.reset_crepe()\n",
    "\n",
    "# Compute features.\n",
    "start_time = time.time()\n",
    "audio_features = ddsp.training.metrics.compute_audio_features(audio)\n",
    "# audio_features['loudness_db'] = audio_features['loudness_db'].astype(np.float32)\n",
    "audio_features['loudness_db'] = audio_features[\"loudness_db\"].numpy().astype(\"float32\")\n",
    "audio_features_mod = None\n",
    "print('Audio features took %.1f seconds' % (time.time() - start_time))\n",
    "\n",
    "TRIM = -15\n",
    "# Plot Features.\n",
    "fig, ax = plt.subplots(nrows=3,\n",
    "                       ncols=1,\n",
    "                       sharex=True,\n",
    "                       figsize=(6, 8))\n",
    "ax[0].plot(audio_features['loudness_db'][:TRIM])\n",
    "ax[0].set_ylabel('loudness_db')\n",
    "\n",
    "ax[1].plot(librosa.hz_to_midi(audio_features['f0_hz'][:TRIM]))\n",
    "ax[1].set_ylabel('f0 [midi]')\n",
    "\n",
    "ax[2].plot(audio_features['f0_confidence'][:TRIM])\n",
    "ax[2].set_ylabel('f0 confidence')\n",
    "_ = ax[2].set_xlabel('Time step [frame]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "af = {k: v.copy() for k, v in audio_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2359a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "af0 = {k: v.copy() for k, v in audio_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path here\n",
    "model_dir =\"../data/models/0323-halfrave-1\"\n",
    "gin_file = os.path.join(model_dir, \"operative_config-0.gin\")\n",
    "\n",
    "#foo (1, 64000) (1, 2500, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8971bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the original DDSP model\n",
    "# model_dir =\"../data/train\"\n",
    "# gin_file = os.path.join(model_dir, \"operative_config-2700.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gin.enter_interactive_mode()\n",
    "\n",
    "# Load the dataset statistics.\n",
    "DATASET_STATS = None\n",
    "dataset_stats_file = os.path.join(model_dir, 'dataset_statistics.pkl')\n",
    "print(f'Loading dataset statistics from {dataset_stats_file}')\n",
    "try:\n",
    "    if tf.io.gfile.exists(dataset_stats_file):\n",
    "        with tf.io.gfile.GFile(dataset_stats_file, 'rb') as f:\n",
    "            DATASET_STATS = pickle.load(f)\n",
    "except Exception as err:\n",
    "    print('Loading dataset statistics from pickle failed: {}.'.format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thesis.timbre_transfer_util import adjust_batch\n",
    "af = {k: v.copy() for k, v in audio_features.items()}\n",
    "audio_features_mod = adjust_batch(af, DATASET_STATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbaefcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_on = audio_features_mod[\"mask_on\"][0]\n",
    "\n",
    "# Plot Features.\n",
    "has_mask = int(mask_on is not None)\n",
    "n_plots = 3 if has_mask else 2\n",
    "fig, axes = plt.subplots(nrows=n_plots,\n",
    "                         ncols=1,\n",
    "                         sharex=True,\n",
    "                         figsize=(2 * n_plots, 8))\n",
    "\n",
    "if has_mask:\n",
    "    threshold = 1\n",
    "    ax = axes[0]\n",
    "    ax.plot(np.ones_like(mask_on[:TRIM]) * threshold, 'k:')\n",
    "    # ax.plot(note_on_value[:TRIM])\n",
    "    ax.plot(mask_on[:TRIM])\n",
    "    ax.set_ylabel('Note-on Mask')\n",
    "    ax.set_xlabel('Time step [frame]')\n",
    "    ax.legend(['Threshold', 'Likelihood', 'Mask'])\n",
    "\n",
    "ax = axes[0 + has_mask]\n",
    "ax.plot(audio_features['loudness_db'][:TRIM])\n",
    "ax.plot(audio_features_mod['loudness_db'][0,:TRIM])\n",
    "ax.set_ylabel('loudness_db')\n",
    "ax.legend(['Original', 'Adjusted'])\n",
    "\n",
    "ax = axes[1 + has_mask]\n",
    "ax.plot(librosa.hz_to_midi(audio_features['f0_hz'][:TRIM]))\n",
    "ax.plot(librosa.hz_to_midi(audio_features_mod['f0_hz'][0,:TRIM]))\n",
    "ax.set_ylabel('f0 [midi]')\n",
    "_ = ax.legend(['Original', 'Adjusted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc7c1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc72ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "af = audio_features if audio_features_mod is None else audio_features_mod\n",
    "\n",
    "# Run a batch of predictions.\n",
    "start_time = time.time()\n",
    "outputs = model(af, training=False)\n",
    "audio_gen = model.get_audio_from_outputs(outputs)\n",
    "print('Prediction took %.1f seconds' % (time.time() - start_time))\n",
    "\n",
    "# Plot\n",
    "print('Original')\n",
    "# play(audio)\n",
    "IPython.display.display(IPython.display.Audio(audio, rate=DEFAULT_SAMPLE_RATE))\n",
    "\n",
    "print('Resynthesis')\n",
    "IPython.display.display(IPython.display.Audio(audio_gen[:,:], rate=DEFAULT_SAMPLE_RATE))\n",
    "# play(audio_gen)\n",
    "specplot(audio)\n",
    "plt.title(\"Original\")\n",
    "\n",
    "specplot(audio_gen[:,:])\n",
    "_ = plt.title(\"Resynthesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd6f051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

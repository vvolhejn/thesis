{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import List\n",
    "import os\n",
    "import note_seq\n",
    "import tensorflow as tf\n",
    "from codetiming import Timer\n",
    "import tqdm\n",
    "import gin\n",
    "import numpy as np\n",
    "from rich.table import Table\n",
    "from rich.console import Console\n",
    "from rich.jupyter import print as pprint\n",
    "\n",
    "import tf2onnx.convert\n",
    "import onnxruntime as ort\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "from ddsp.losses import SpectralLoss\n",
    "from ddsp.training.ddsp_export import get_representative_dataset\n",
    "import openvino.runtime\n",
    "from onnxruntime.quantization import quantize_dynamic, quantize_static, QuantType, QuantFormat, CalibrationDataReader\n",
    "\n",
    "from thesis.notebook_util import play_audio\n",
    "\n",
    "gin.enter_interactive_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class InferenceDecoder:\n",
    "\n",
    "    def __call__(self, f0_scaled, pw_scaled):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class TFLiteDecoder(InferenceDecoder):\n",
    "    def __init__(self, model_path):\n",
    "        self.name = f\"TFLite: {os.path.basename(model_path)}\"\n",
    "\n",
    "        #tflite_file_path = \"model_quantized.tflite\" if quantized else \"model_unquantized.tflite\"\n",
    "        #tflite_file_path = os.path.join(model_dir, \"export/tflite\", tflite_file_path)\n",
    "        interpreter = tf.lite.Interpreter(model_path)\n",
    "        self.my_signature = interpreter.get_signature_runner()\n",
    "\n",
    "    def __call__(self, f0_scaled, pw_scaled):\n",
    "        features = self.my_signature(\n",
    "            f0_scaled=f0_scaled,\n",
    "            pw_scaled=pw_scaled,\n",
    "        )\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "class TensorFlowDecoder(InferenceDecoder):\n",
    "    def __init__(self, model):\n",
    "        self.name = \"TensorFlow\"\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, f0_scaled, pw_scaled):\n",
    "        features = self.model.decoder({\"f0_scaled\": f0_scaled, \"pw_scaled\": pw_scaled})\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "class ONNXRuntimeDecoder(InferenceDecoder):\n",
    "    def __init__(self, model_path, params_as_list=False):\n",
    "        self.name = f\"ONNX Runtime: {os.path.basename(model_path)}\"\n",
    "        self.session = ort.InferenceSession(os.path.join(model_dir, model_path))\n",
    "        self.params_as_list = params_as_list\n",
    "\n",
    "    def __call__(self, f0_scaled, pw_scaled):\n",
    "        keys = [\"amps\", \"harmonic_distribution\", \"noise_magnitudes\"]\n",
    "\n",
    "        if self.params_as_list:\n",
    "            params = {\n",
    "                \"args_0\": f0_scaled.numpy()[0, :, 0],\n",
    "                \"args_1\": pw_scaled.numpy()[0, :, 0],\n",
    "            }\n",
    "        else:\n",
    "            params = {\n",
    "                \"f0_scaled\": f0_scaled.numpy()[0, :, 0],\n",
    "                \"pw_scaled\": pw_scaled.numpy()[0, :, 0],\n",
    "            }\n",
    "\n",
    "        features = self.session.run(keys, params)\n",
    "\n",
    "        return dict(zip(keys, features))\n",
    "\n",
    "\n",
    "class OpenVINODecoder(InferenceDecoder):\n",
    "    def __init__(self, model_path):\n",
    "        self.name = f\"OpenVINO: {os.path.basename(model_path)}\"\n",
    "        self.ie = openvino.runtime.Core()\n",
    "        # \"/Volumes/euler/export/openvino/model_unquantized.xml\"\n",
    "        model = self.ie.read_model(model=model_path)\n",
    "        self.compiled_model = self.ie.compile_model(model=model, device_name=\"CPU\")\n",
    "        self.input_names = [x.any_name for x in self.compiled_model.inputs]\n",
    "        self.request = self.compiled_model.create_infer_request()\n",
    "\n",
    "\n",
    "    def __call__(self, f0_scaled, pw_scaled):\n",
    "        keys = [\"amps\", \"harmonic_distribution\", \"noise_magnitudes\"]\n",
    "\n",
    "        self.request.infer({self.input_names[0]: f0_scaled[0, :, 0], self.input_names[1]: pw_scaled[0, :, 0]})\n",
    "\n",
    "        return dict([(k, self.request.get_tensor(k).data) for k in keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def main(decoders: List[InferenceDecoder]):\n",
    "    model_dir = \"/Volumes/euler/\"\n",
    "\n",
    "    with gin.unlock_config():\n",
    "        operative_config = ddsp.training.train_util.get_latest_operative_config(model_dir)\n",
    "        gin.parse_config_file(operative_config, skip_unknown=True)\n",
    "        # print(gin.config.config_str())\n",
    "\n",
    "    representative_dataset = get_representative_dataset(\n",
    "        \"/Users/vaclav/prog/thesis/data/violin2/violin2.tfrecord*\",\n",
    "        include_f0_hz=True,\n",
    "    )\n",
    "\n",
    "    model = ddsp.training.models.get_model()\n",
    "    checkpoint_path = tf.train.latest_checkpoint(model_dir, latest_filename=None)\n",
    "\n",
    "    assert checkpoint_path is not None, f\"No checkpoint found in {model_dir}\"\n",
    "\n",
    "    model.restore(checkpoint_path, verbose=False)\n",
    "\n",
    "    decoders.append(TensorFlowDecoder(model))\n",
    "\n",
    "    loss_fn = SpectralLoss(logmag_weight=1.0)\n",
    "    assert loss_fn.logmag_weight == 1.0\n",
    "    # print(\"Logmag weight (should be 1.0 to match operative config):\", loss.logmag_weight)\n",
    "\n",
    "    decoder_names = set()\n",
    "    for decoder in decoders:\n",
    "        assert decoder.name not in decoder_names, f\"Non-unique decoder name {decoder.name}\"\n",
    "        decoder_names.add(decoder.name)\n",
    "\n",
    "    losses = dict([(name, []) for name in decoder_names])\n",
    "\n",
    "    for i, batch in enumerate(tqdm.tqdm(representative_dataset())):\n",
    "        outputs = {}\n",
    "\n",
    "        for decoder in decoders:\n",
    "            with Timer(decoder.name, logger=None):\n",
    "                features = decoder(f0_scaled=batch[0], pw_scaled=batch[1])\n",
    "\n",
    "            features[\"f0_hz\"] = batch[2]\n",
    "\n",
    "            # Finish the computation in normal TensorFlow\n",
    "            outputs[decoder.name] = model.processor_group(features, return_outputs_dict=True)\n",
    "\n",
    "            losses[decoder.name].append(loss_fn(batch[3], outputs[decoder.name][\"signal\"]))\n",
    "\n",
    "        if i == 50:\n",
    "            break\n",
    "\n",
    "    table = Table(title=\"Summary\")\n",
    "    table.add_column(\"Name\")\n",
    "    table.add_column(\"Loss\")\n",
    "    table.add_column(\"Inference time\")\n",
    "\n",
    "    for decoder in decoders:\n",
    "        table.add_row(\n",
    "            decoder.name,\n",
    "            f\"{np.mean(losses[decoder.name]):.3f}\",\n",
    "            f\"{np.array(Timer.timers._timings[decoder.name])[1:].mean():.4f}\",\n",
    "        )\n",
    "\n",
    "    #Console().print(table)\n",
    "    pprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_dir = \"/Volumes/euler\"\n",
    "export_dir = \"/Volumes/euler/export\"\n",
    "\n",
    "main([\n",
    "    # TFLiteDecoder(os.path.join(export_dir, \"tflite/model_dynamic_range_quantized.tflite\")),\n",
    "    TFLiteDecoder(os.path.join(export_dir, \"tflite/model_unquantized.tflite\")),\n",
    "    ONNXRuntimeDecoder(os.path.join(export_dir, \"onnx/model_unquantized.onnx\")),\n",
    "    # ONNXRuntimeDecoder(os.path.join(export_dir, \"onnx/model_onnx_q_dynamic.onnx\")),\n",
    "    # ONNXRuntimeDecoder(os.path.join(export_dir, \"onnx/model_from_keras.onnx\"), params_as_list=True),\n",
    "    # ONNXRuntimeDecoder(os.path.join(export_dir, \"onnx/model_onnx_q_static.onnx\")),\n",
    "    OpenVINODecoder(os.path.join(export_dir, \"openvino/model_unquantized.xml\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_fp32 = os.path.join(model_dir, 'export/onnx/model_unquantized.onnx')\n",
    "model_q_static = os.path.join(model_dir, 'export/onnx/model_onnx_q_static.onnx')\n",
    "\n",
    "quantize_static(\n",
    "    model_fp32,\n",
    "    model_q_static,\n",
    "    ONNXDataReader(),\n",
    "    # activation_type=QuantType.QUInt8,\n",
    "    # weight_type=QuantType.QUInt8,\n",
    "    nodes_to_exclude=[\"StatefulPartitionedCall/dilated_conv_decoder_1/split\"],\n",
    "    per_channel=False,\n",
    "    quant_format=QuantFormat.QOperator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# QDQ\n",
    "# S8S8 - Could not find an implementation for QuantizeLinear(13) node\n",
    "# U8U8 - same\n",
    "# U8S8 (activation unsigned, weights signed) - same\n",
    "# S8U8 - ONNXRuntime quantization doesn't support data format:activation_type=QuantType.QInt8, weight_type = QuantType.QUInt8\n",
    "\n",
    "# QOperator\n",
    "# S8S8 - works, huge loss, 2x slower than unquantized\n",
    "# U8U8 - works, huge loss, 2x slower than unquantized\n",
    "# U8S8 - works, huge loss, 2x slower than unquantized\n",
    "# S8U8 - ONNXRuntime quantization doesn't support data format:activation_type=QuantType.QInt8, weight_type = QuantType.QUInt8\n",
    "\n",
    "# Please use QuantFormat.QDQ for activation type QInt8 and weight type QInt8. Or it will lead to bad performance on x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Breaks!\n",
    "# TFLiteDecoder(os.path.join(model_dir, \"export/tflite/model_quantized.tflite\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, quantize_static, QuantType, QuantFormat, CalibrationDataReader\n",
    "\n",
    "#model_fp32 = os.path.join(model_dir, 'export/onnx/model_unquantized.onnx')\n",
    "model_fp32 = os.path.join(model_dir, 'export/onnx/model_unquantized.onnx')\n",
    "model_q_dynamic = os.path.join(model_dir, 'export/onnx/model_onnx_q_dynamic.onnx')\n",
    "\n",
    "quantized_model = quantize_dynamic(\n",
    "    model_fp32,\n",
    "    model_q_dynamic,\n",
    "    weight_type=QuantType.QUInt8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ONNXDataReader(CalibrationDataReader):\n",
    "    def __init__(self):\n",
    "        self.dataset = get_representative_dataset(\"/Users/vaclav/prog/thesis/data/violin2/violin2.tfrecord*\")()\n",
    "\n",
    "    def get_next(self):\n",
    "        batch = next(self.dataset, None)\n",
    "        if batch is None:\n",
    "            return None\n",
    "        else:\n",
    "            return {\n",
    "                \"f0_scaled\": batch[0].numpy()[0, :, 0],\n",
    "                \"pw_scaled\": batch[1].numpy()[0, :, 0],\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "quantize_static(\n",
    "    os.path.join(model_dir, 'export/onnx/model_from_keras.onnx'),\n",
    "    os.path.join(model_dir, 'export/onnx/model_from_keras_q_static.onnx'),\n",
    "    ONNXDataReader(),\n",
    "    activation_type=QuantType.QUInt8,\n",
    "    weight_type=QuantType.QUInt8,\n",
    "    per_channel=False,\n",
    "    quant_format=QuantFormat.QDQ,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session = ort.InferenceSession(os.path.join(export_dir, \"onnx/model_from_keras.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session.get_inputs()[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session.run(\n",
    "    [\"amps\", \"harmonic_distribution\", \"noise_magnitudes\"],\n",
    "    #[np.zeros([201], dtype=np.float32), np.zeros([201], dtype=np.float32)],\n",
    "    {\n",
    "        \"args_0\": np.zeros([201], dtype=np.float32),\n",
    "        \"args_1\": np.zeros([201], dtype=np.float32)\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnxruntime.quantization import quantize_dynamic, quantize_static, QuantType, QuantFormat, CalibrationDataReader\n",
    "\n",
    "class DummyDataReader(CalibrationDataReader):\n",
    "    def __init__(self):\n",
    "        self.dataset = get_representative_dataset(\"/Users/vaclav/prog/thesis/data/violin2/violin2.tfrecord*\")()\n",
    "\n",
    "    def get_next(self):\n",
    "        batch = next(self.dataset, None)\n",
    "        if batch is None:\n",
    "            return None\n",
    "        else:\n",
    "            return {\n",
    "                \"input\": batch[0].numpy()[0, :10*10, 0].reshape([1, 10, 10, 1]),\n",
    "            }\n",
    "\n",
    "def test_dummy():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation=tf.nn.relu)\n",
    "    ])\n",
    "    input_shape = [1, 10, 10, 1]\n",
    "    model.build(input_shape)\n",
    "\n",
    "    onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "        model,\n",
    "        input_signature=[tf.TensorSpec((1, 10, 10, 1), name=\"input\")],\n",
    "        opset=13,\n",
    "    )\n",
    "    path = \"/tmp/dummy_model.onnx\"\n",
    "    path_q = \"/tmp/dummy_model_q.onnx\"\n",
    "    onnx.save(onnx_model, path)\n",
    "\n",
    "    # quantized_model = quantize_dynamic(\n",
    "    #     path,\n",
    "    #     path_q,\n",
    "    #     # weight_type=QuantType.QUInt8\n",
    "    # )\n",
    "\n",
    "    quantize_static(\n",
    "        path,\n",
    "        path_q,\n",
    "        # weight_type=QuantType.QUInt8\n",
    "        # quant_format=QuantFormat.QDQ,\n",
    "        # activation_type=QuantType.QUInt8,\n",
    "        # weight_type=QuantType.QUInt8,\n",
    "        calibration_data_reader=DummyDataReader(),\n",
    "        per_channel=True,\n",
    "        #quant_format=QuantFormat.QDQ,\n",
    "        quant_format=QuantFormat.QOperator,\n",
    "    )\n",
    "\n",
    "    session = onnxruntime.InferenceSession(path_q)\n",
    "    print(session.get_outputs()[0].name)\n",
    "    features, = session.run(\n",
    "        [session.get_outputs()[0].name],\n",
    "        {\"input\": np.ones(input_shape, dtype=np.float32)}\n",
    "    )\n",
    "    print(features)\n",
    "\n",
    "\n",
    "test_dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

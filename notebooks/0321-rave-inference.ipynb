{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf9aef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import thesis.rave\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import crepe\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "from ddsp.colab.colab_utils import (\n",
    "    auto_tune, get_tuning_factor, download,\n",
    "    play, record, specplot, upload, audio_bytes_to_np,\n",
    "    DEFAULT_SAMPLE_RATE)\n",
    "from ddsp.training.postprocessing import (\n",
    "    detect_notes, fit_quantile_transform\n",
    ")\n",
    "import gin\n",
    "# from google.colab import files\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import tensorflow.compat.v2 as tf\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import einops\n",
    "\n",
    "# Helper Functions\n",
    "# sample_rate = DEFAULT_SAMPLE_RATE  # 16000\n",
    "sample_rate = 16000\n",
    "\n",
    "def play_audio(audio):\n",
    "    audio = np.array(audio)\n",
    "    audio = np.squeeze(audio)\n",
    "    IPython.display.display(IPython.display.Audio(audio, rate=16000))\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21435309",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_f = open(\"../data/audio/violin/II. Double.mp3\", \"rb\")\n",
    "wav_bytes = input_f.read()\n",
    "audio = audio_bytes_to_np(wav_bytes)\n",
    "audio = audio[:sample_rate * 10]\n",
    "\n",
    "if len(audio.shape) == 1:\n",
    "    audio = audio[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb49c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "specplot(audio)\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "IPython.display.Audio(audio, rate=DEFAULT_SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac550b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "# Setup the session.\n",
    "ddsp.spectral_ops.reset_crepe()\n",
    "\n",
    "# Compute features.\n",
    "start_time = time.time()\n",
    "audio_features = ddsp.training.metrics.compute_audio_features(audio)\n",
    "# audio_features['loudness_db'] = audio_features['loudness_db'].astype(np.float32)\n",
    "audio_features['loudness_db'] = audio_features[\"loudness_db\"].numpy().astype(\"float32\")\n",
    "audio_features_mod = None\n",
    "print('Audio features took %.1f seconds' % (time.time() - start_time))\n",
    "\n",
    "TRIM = -15\n",
    "# Plot Features.\n",
    "fig, ax = plt.subplots(nrows=3,\n",
    "                       ncols=1,\n",
    "                       sharex=True,\n",
    "                       figsize=(6, 8))\n",
    "ax[0].plot(audio_features['loudness_db'][:TRIM])\n",
    "ax[0].set_ylabel('loudness_db')\n",
    "\n",
    "ax[1].plot(librosa.hz_to_midi(audio_features['f0_hz'][:TRIM]))\n",
    "ax[1].set_ylabel('f0 [midi]')\n",
    "\n",
    "ax[2].plot(audio_features['f0_confidence'][:TRIM])\n",
    "ax[2].set_ylabel('f0 confidence')\n",
    "_ = ax[2].set_xlabel('Time step [frame]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b8d6f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 109s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d663a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set path here\n",
    "model_dir =\"../data/models/0323-halfrave-1\"\n",
    "gin_file = os.path.join(model_dir, \"operative_config-0.gin\")\n",
    "\n",
    "#foo (1, 64000) (1, 2500, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92cd547",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for the original DDSP model\n",
    "# model_dir =\"../data/train\"\n",
    "# gin_file = os.path.join(model_dir, \"operative_config-2700.gin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903d635",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gin.enter_interactive_mode()\n",
    "\n",
    "# Load the dataset statistics.\n",
    "DATASET_STATS = None\n",
    "dataset_stats_file = os.path.join(model_dir, 'dataset_statistics.pkl')\n",
    "print(f'Loading dataset statistics from {dataset_stats_file}')\n",
    "try:\n",
    "    if tf.io.gfile.exists(dataset_stats_file):\n",
    "        with tf.io.gfile.GFile(dataset_stats_file, 'rb') as f:\n",
    "            DATASET_STATS = pickle.load(f)\n",
    "except Exception as err:\n",
    "    print('Loading dataset statistics from pickle failed: {}.'.format(err))\n",
    "\n",
    "# Parse gin config,\n",
    "with gin.unlock_config():\n",
    "    gin.parse_config_file(gin_file, skip_unknown=True)\n",
    "\n",
    "# Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
    "ckpt_files = [f for f in tf.io.gfile.listdir(model_dir) if 'ckpt' in f]\n",
    "ckpt_name = ckpt_files[0].split('.')[0]\n",
    "ckpt = os.path.join(model_dir, ckpt_name)\n",
    "\n",
    "# Ensure dimensions and sampling rates are equal\n",
    "time_steps_train = gin.query_parameter('F0LoudnessPreprocessor.time_steps')\n",
    "\n",
    "# n_samples_train = gin.query_parameter('n_samples')\n",
    "# TODO: How to read this from gin? `gin.query_parameter(\"NEWTHarmonic.samples_train\")`\n",
    "# returns \"%n_samples\" rather than the value of the `n_samples` macro.\n",
    "n_samples_train = 64000\n",
    "# print(time_steps_train, n_samples_train)\n",
    "hop_size = int(n_samples_train / time_steps_train)\n",
    "\n",
    "\n",
    "time_steps = int(audio.shape[1] / hop_size)\n",
    "n_samples = time_steps * hop_size\n",
    "\n",
    "# print(\"===Trained model===\")\n",
    "# print(\"Time Steps\", time_steps_train)\n",
    "# print(\"Samples\", n_samples_train)\n",
    "# print(\"Hop Size\", hop_size)\n",
    "# print(\"\\n===Resynthesis===\")\n",
    "# print(\"Time Steps\", time_steps)\n",
    "# print(\"Samples\", n_samples)\n",
    "# print('')\n",
    "\n",
    "gin_params = [\n",
    "    'RAVEWaveformGenerator.n_samples = {}'.format(n_samples),\n",
    "    'MultibandFilteredNoise.n_samples = {}'.format(n_samples),\n",
    "    'F0LoudnessPreprocessor.time_steps = {}'.format(time_steps),\n",
    "    'oscillator_bank.use_angular_cumsum = True',  # Avoids cumsum accumulation errors.\n",
    "]\n",
    "\n",
    "with gin.unlock_config():\n",
    "    gin.parse_config(gin_params)\n",
    "\n",
    "# Trim all input vectors to correct lengths\n",
    "for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
    "    audio_features[key] = audio_features[key][:time_steps]\n",
    "audio_features['audio'] = audio_features['audio'][:, :n_samples]\n",
    "\n",
    "# Set up the model just to predict audio given new conditioning\n",
    "model = ddsp.training.models.Autoencoder()\n",
    "model.restore(ckpt)\n",
    "\n",
    "# Build model by running a batch through it.\n",
    "start_time = time.time()\n",
    "_ = model(audio_features, training=False)\n",
    "print('Restoring model took %.1f seconds' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b331da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title Modify conditioning\n",
    "\n",
    "#@markdown These models were not explicitly trained to perform timbre transfer, so they may sound unnatural if the incoming loudness and frequencies are very different then the training data (which will always be somewhat true).\n",
    "\n",
    "\n",
    "#@markdown ## Note Detection\n",
    "\n",
    "#@markdown You can leave this at 1.0 for most cases\n",
    "threshold = 1.5  #@param {type:\"slider\", min: 0.0, max:2.0, step:0.01}\n",
    "\n",
    "#@markdown ## Automatic\n",
    "\n",
    "ADJUST = True  #@param{type:\"boolean\"}\n",
    "\n",
    "#@markdown Quiet parts without notes detected (dB)\n",
    "quiet = 20  #@param {type:\"slider\", min: 0, max:60, step:1}\n",
    "\n",
    "#@markdown Force pitch to nearest note (amount)\n",
    "autotune = 0  #@param {type:\"slider\", min: 0.0, max:1.0, step:0.1}\n",
    "\n",
    "#@markdown ## Manual\n",
    "\n",
    "\n",
    "#@markdown Shift the pitch (octaves)\n",
    "pitch_shift = -1  #@param {type:\"slider\", min:-2, max:2, step:1}\n",
    "\n",
    "#@markdown Adjust the overall loudness (dB)\n",
    "loudness_shift = 0  #@param {type:\"slider\", min:-20, max:20, step:1}\n",
    "\n",
    "audio_features_mod = {k: v.copy() for k, v in audio_features.items()}\n",
    "\n",
    "\n",
    "## Helper functions.\n",
    "def shift_ld(audio_features, ld_shift=0.0):\n",
    "    \"\"\"Shift loudness by a number of ocatves.\"\"\"\n",
    "    audio_features['loudness_db'] += ld_shift\n",
    "    return audio_features\n",
    "\n",
    "\n",
    "def shift_f0(audio_features, pitch_shift=0.0):\n",
    "    \"\"\"Shift f0 by a number of ocatves.\"\"\"\n",
    "    audio_features['f0_hz'] *= 2.0 ** (pitch_shift)\n",
    "    audio_features['f0_hz'] = np.clip(audio_features['f0_hz'],\n",
    "                                      0.0,\n",
    "                                      librosa.midi_to_hz(110.0))\n",
    "    return audio_features\n",
    "\n",
    "\n",
    "mask_on = None\n",
    "\n",
    "if ADJUST and DATASET_STATS is not None:\n",
    "    # Detect sections that are \"on\".\n",
    "    mask_on, note_on_value = detect_notes(audio_features['loudness_db'],\n",
    "                                          audio_features['f0_confidence'],\n",
    "                                          threshold)\n",
    "\n",
    "    if np.any(mask_on):\n",
    "        # Shift the pitch register.\n",
    "        target_mean_pitch = DATASET_STATS['mean_pitch']\n",
    "        pitch = ddsp.core.hz_to_midi(audio_features['f0_hz'])\n",
    "        mean_pitch = np.mean(pitch[mask_on])\n",
    "        p_diff = target_mean_pitch - mean_pitch\n",
    "        p_diff_octave = p_diff / 12.0\n",
    "        round_fn = np.floor if p_diff_octave > 1.5 else np.ceil\n",
    "        p_diff_octave = round_fn(p_diff_octave)\n",
    "        audio_features_mod = shift_f0(audio_features_mod, p_diff_octave)\n",
    "\n",
    "        # Quantile shift the note_on parts.\n",
    "        _, loudness_norm = fit_quantile_transform(\n",
    "            audio_features['loudness_db'],\n",
    "            mask_on,\n",
    "            inv_quantile=DATASET_STATS['quantile_transform'])\n",
    "\n",
    "        # Turn down the note_off parts.\n",
    "        mask_off = np.logical_not(mask_on)\n",
    "        loudness_norm[mask_off] -= quiet * (1.0 - note_on_value[mask_off][:, np.newaxis])\n",
    "        loudness_norm = np.reshape(loudness_norm, audio_features['loudness_db'].shape)\n",
    "\n",
    "        audio_features_mod['loudness_db'] = loudness_norm\n",
    "\n",
    "        # Auto-tune.\n",
    "        if autotune:\n",
    "            f0_midi = np.array(ddsp.core.hz_to_midi(audio_features_mod['f0_hz']))\n",
    "            tuning_factor = get_tuning_factor(f0_midi, audio_features_mod['f0_confidence'], mask_on)\n",
    "            f0_midi_at = auto_tune(f0_midi, tuning_factor, mask_on, amount=autotune)\n",
    "            audio_features_mod['f0_hz'] = ddsp.core.midi_to_hz(f0_midi_at)\n",
    "\n",
    "    else:\n",
    "        print('\\nSkipping auto-adjust (no notes detected or ADJUST box empty).')\n",
    "\n",
    "else:\n",
    "    print('\\nSkipping auto-adujst (box not checked or no dataset statistics found).')\n",
    "\n",
    "# Manual Shifts.\n",
    "audio_features_mod = shift_ld(audio_features_mod, loudness_shift)\n",
    "audio_features_mod = shift_f0(audio_features_mod, pitch_shift)\n",
    "\n",
    "# audio_features_mod[\"f0_hz\"] = np.sin(np.linspace(0, 20, audio_features_mod[\"f0_hz\"].shape[0])) * 100 + 600. + np.linspace(0, 500, audio_features_mod[\"f0_hz\"].shape[0])\n",
    "\n",
    "# Plot Features.\n",
    "has_mask = int(mask_on is not None)\n",
    "n_plots = 3 if has_mask else 2\n",
    "fig, axes = plt.subplots(nrows=n_plots,\n",
    "                         ncols=1,\n",
    "                         sharex=True,\n",
    "                         figsize=(2 * n_plots, 8))\n",
    "\n",
    "if has_mask:\n",
    "    ax = axes[0]\n",
    "    ax.plot(np.ones_like(mask_on[:TRIM]) * threshold, 'k:')\n",
    "    ax.plot(note_on_value[:TRIM])\n",
    "    ax.plot(mask_on[:TRIM])\n",
    "    ax.set_ylabel('Note-on Mask')\n",
    "    ax.set_xlabel('Time step [frame]')\n",
    "    ax.legend(['Threshold', 'Likelihood', 'Mask'])\n",
    "\n",
    "ax = axes[0 + has_mask]\n",
    "ax.plot(audio_features['loudness_db'][:TRIM])\n",
    "ax.plot(audio_features_mod['loudness_db'][:TRIM])\n",
    "ax.set_ylabel('loudness_db')\n",
    "ax.legend(['Original', 'Adjusted'])\n",
    "\n",
    "ax = axes[1 + has_mask]\n",
    "ax.plot(librosa.hz_to_midi(audio_features['f0_hz'][:TRIM]))\n",
    "ax.plot(librosa.hz_to_midi(audio_features_mod['f0_hz'][:TRIM]))\n",
    "ax.set_ylabel('f0 [midi]')\n",
    "_ = ax.legend(['Original', 'Adjusted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7b104",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title #Resynthesize Audio\n",
    "\n",
    "af = audio_features if audio_features_mod is None else audio_features_mod\n",
    "\n",
    "# Run a batch of predictions.\n",
    "start_time = time.time()\n",
    "outputs = model(af, training=False)\n",
    "audio_gen = model.get_audio_from_outputs(outputs)\n",
    "print('Prediction took %.1f seconds' % (time.time() - start_time))\n",
    "\n",
    "# Plot\n",
    "print('Original')\n",
    "# play(audio)\n",
    "IPython.display.display(IPython.display.Audio(audio, rate=DEFAULT_SAMPLE_RATE))\n",
    "\n",
    "print('Resynthesis')\n",
    "IPython.display.display(IPython.display.Audio(audio_gen[:,:], rate=DEFAULT_SAMPLE_RATE))\n",
    "# play(audio_gen)\n",
    "specplot(audio)\n",
    "plt.title(\"Original\")\n",
    "\n",
    "specplot(audio_gen[:,:])\n",
    "_ = plt.title(\"Resynthesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c9b6d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "audio_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45511ed0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc72c96",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from thesis.util import resample\n",
    "from thesis.pqmf import PQMFBank\n",
    "pqmf = PQMFBank(n_bands=16, attenuation=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88327327",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "waveform = pqmf.synthesis(outputs[\"rave_waveform_generator\"][\"signal\"])\n",
    "play_audio(waveform)\n",
    "specplot(waveform[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fbd80",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noise = pqmf.synthesis(outputs[\"multiband_filtered_noise\"][\"signal\"])\n",
    "play_audio(noise)\n",
    "specplot(noise[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b566d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(outputs[\"crop\"][\"signal\"][0,::100,50:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff2935",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp0 = outputs[\"rave_waveform_generator\"][\"signal\"].numpy()\n",
    "a2 = resample(temp0, temp0.shape[1] * 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa1eec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66f18e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(a2[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8407f58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import thesis.rave\n",
    "waveform_gen: thesis.rave.RAVEWaveformGenerator = model.processor_group.processors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40897b9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "control_embedding = outputs[\"crop\"][\"signal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe1cefe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loudness = waveform_gen.loud_gen(control_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bac817",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "waveform = tf.tanh(waveform_gen.wave_gen(control_embedding))\n",
    "waveform_single = pqmf.synthesis(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662a5bc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(loudness[0,::100,0])\n",
    "plt.plot(waveform_single[0,::100,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21181b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(waveform[0,1000:1050,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d13f9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "control_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c9f03",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "specplot(waveform[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915df80",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(waveform_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bedd982",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "waveform_gen.call(waveform_gen_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc42ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "import numpy as np\n",
    "import IPython.display\n",
    "\n",
    "import gin\n",
    "gin.enter_interactive_mode()\n",
    "\n",
    "from thesis.notebook_util import play_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_provider = ddsp.training.data.TFRecordProvider(\n",
    "    file_pattern=\"/Users/vaclav/prog/thesis/data/violin2/violin2.tfrecord*\",\n",
    "    frame_rate=50,\n",
    "    centered=True,\n",
    ")\n",
    "def representative_data_gen():\n",
    "    dataset = data_provider.get_batch(batch_size=1, shuffle=True, repeats=1)\n",
    "    for i, batch in zip(range(10), dataset):\n",
    "        # Model has only one input so each data point has one element.\n",
    "        yield [batch[\"audio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = list(representative_data_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TFLITE_FILE_PATH = \"/cluster/scratch/vvolhejn/models/0503-ddspae-vst-cnn-2/export/tflite/model.tflite\"\n",
    "TFLITE_FILE_PATH = \"/Volumes/euler/export/tflite/model_quantized.tflite\"\n",
    "interpreter = tf.lite.Interpreter(TFLITE_FILE_PATH)\n",
    "my_signature = interpreter.get_signature_runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "if input_details['dtype'] == np.int8:\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    test_image = test_image / input_scale + input_zero_point\n",
    "    print(input_scale, input_zero_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# my_signature is callable with input as arguments.\n",
    "#output = my_signature(x=tf.constant([1.0], shape=(1,10), dtype=tf.float32))\n",
    "n_samples = 64000\n",
    "\n",
    "audio = tf.cast(tf.reshape(tf.sin(tf.linspace(0, 2000, 64000) + (tf.linspace(0, 1, 64000) ** 2) * 2000), [64000]), tf.float32)\n",
    "audio = tf.reshape(x[0], [64000])\n",
    "\n",
    "output = my_signature(\n",
    "    audio=tf.constant(audio, shape=(n_samples,), dtype=tf.float32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "harm_audio, final_phase = ddsp.core.streaming_harmonic_synthesis(\n",
    "    frequencies=output[\"f0_hz\"],\n",
    "    amplitudes=output[\"amplitudes\"],\n",
    "    harmonic_distribution=output[\"harmonic_distribution\"],\n",
    "    initial_phase=tf.constant([0], shape=(1,1,1), dtype=tf.float32),\n",
    "    n_samples=n_samples,\n",
    "    sample_rate=16000,\n",
    "    amp_resample_method=\"linear\")\n",
    "\n",
    "filtered_noise = ddsp.synths.FilteredNoise(n_samples=n_samples, window_size=0)\n",
    "\n",
    "noise_audio = filtered_noise.get_signal(tf.expand_dims(output[\"noise_magnitudes\"], axis=0))\n",
    "audio_out = harm_audio + noise_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "play_audio(audio_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_signature.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test(layers_per_stack, kernel_size, stacks):\n",
    "    dec = ddsp.training.decoders.DilatedConvDecoder(\n",
    "        ch=128,\n",
    "        layers_per_stack=layers_per_stack,\n",
    "        kernel_size=kernel_size,\n",
    "        norm_type=\"layer\",\n",
    "        input_keys=(\"pw_scaled\", \"f0_scaled\"),\n",
    "        stacks=stacks,\n",
    "        conditioning_keys = None,  # Nothing else than a latent, so no need to consider this separately\n",
    "        precondition_stack = None,  # Not relevant since `conditioning_keys = None`\n",
    "    #    output_splits = (('control_embedding', %decoder_output_channels),)\n",
    "        output_splits = (('amps', 1),\n",
    "                                  ('harmonic_distribution', 60),\n",
    "                                  ('noise_magnitudes', 65)),\n",
    "        resample_after_convolve = False,\n",
    "    )\n",
    "\n",
    "    n = 500\n",
    "    y = dec({\n",
    "        \"pw_scaled\": tf.constant([[0.5] * n], shape=(1,n,1), dtype=tf.float32),\n",
    "        \"f0_scaled\": tf.constant([[0.5] * n], shape=(1,n,1), dtype=tf.float32)\n",
    "    })\n",
    "    dropped_actual = n - y[\"amps\"].shape[1]\n",
    "\n",
    "    stacks_correction = (kernel_size - 1) * (stacks - 1)\n",
    "    dropped_predicted = (kernel_size - 1) * (stacks * 2 ** layers_per_stack) - stacks_correction\n",
    "\n",
    "    msg = (f\"predicted {dropped_predicted} and got {dropped_actual} \"\n",
    "        f\"({layers_per_stack} {kernel_size} {stacks}) -> {dropped_predicted - dropped_actual}\")\n",
    "    print(msg)\n",
    "    # assert dropped_predicted == dropped_actual, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layers_per_stack in [1,2,3]:\n",
    "    for kernel_size in [2,3]:\n",
    "        for stacks in [1,2,3,4]:\n",
    "            test(layers_per_stack, kernel_size, stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dummy_representative_dataset():\n",
    "    for _ in range(100):\n",
    "      pw_scaled=np.random.rand(1, 100, 1).astype(np.float32)\n",
    "      f0_scaled=np.random.rand(1, 100, 1).astype(np.float32)\n",
    "      yield [pw_scaled, f0_scaled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderWrapper(tf.keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dec = ddsp.training.decoders.DilatedConvDecoder(\n",
    "            ch=128,\n",
    "            layers_per_stack=2,\n",
    "            kernel_size=3,\n",
    "            norm_type=\"layer\",\n",
    "            input_keys=(\"pw_scaled\", \"f0_scaled\"),\n",
    "            stacks=2,\n",
    "            conditioning_keys = None,  # Nothing else than a latent, so no need to consider this separately\n",
    "            precondition_stack = None,  # Not relevant since `conditioning_keys = None`\n",
    "        #    output_splits = (('control_embedding', %decoder_output_channels),)\n",
    "            output_splits = (('amps', 1),\n",
    "                                      ('harmonic_distribution', 60),\n",
    "                                      ('noise_magnitudes', 65)),\n",
    "            resample_after_convolve = False,\n",
    "        )\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, pw_scaled, f0_scaled):\n",
    "        features = {\n",
    "            \"pw_scaled\": pw_scaled,\n",
    "            \"f0_scaled\": f0_scaled,\n",
    "        }\n",
    "        outputs = self.dec(features)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "model = DecoderWrapper()\n",
    "\n",
    "# Create a model using high-level tf.keras.* APIs\n",
    "#model.compile(optimizer='sgd', loss='mean_squared_error') # compile the model\n",
    "outputs = model(pw_scaled=np.random.rand(1, 100, 1).astype(np.float32), f0_scaled=np.random.rand(1, 100, 1).astype(np.float32))\n",
    "outputs.keys()\n",
    "# train the model\n",
    "# (to generate a SavedModel) tf.saved_model.save(model, \"saved_model_keras_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "saved_model_path = \"/tmp/wrapper\"\n",
    "model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the model.\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = dummy_representative_dataset\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "dummy_path = '/tmp/dummy_model.tflite'\n",
    "with open(dummy_path, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(dummy_path)\n",
    "dummy_signature = interpreter.get_signature_runner()\n",
    "dummy_signature(\n",
    "    args_0=np.random.rand(1, 100, 1).astype(np.float32), args_1=np.random.rand(1, 100, 1).astype(np.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dummy_signature.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

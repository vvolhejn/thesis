# -*-Python-*-
# Decodes from (loudness, f0). Has a trainable reverb component as well.
# Since it uses a trainable reverb, training data should all be from the same
# acoustic environment.

include 'models/ae.gin'
import thesis.newt

sample_rate = 16000
n_samples = 64000

control_embedding_size = 128
n_waveshapers = 64

Autoencoder:
    encoder = None
    decoder = @decoders.RnnFcDecoder()

RnnFcDecoder:
    rnn_channels = 512
    rnn_type = 'gru'
    ch = 512
    layers_per_stack = 3
    input_keys = ('ld_scaled', 'f0_scaled')
    output_splits = (
        ('control_embedding', 128),
        ('noise_magnitudes', 65),
    )
#RnnFcDecoder.output_splits = (('amps', 1),
#                              ('harmonic_distribution', 60),
#                              ('noise_magnitudes', 65))


# ---------------------
#https://github.com/ben-hayes/neural-waveshaping-synthesis/blob/main/neural_waveshaping_synthesis/models/neural_waveshaping.py#L30


NEWTHarmonic:
    n_harmonics = 101
    sample_rate = %sample_rate
    n_outputs = %n_waveshapers
    n_samples = %n_samples

NEWTWaveshaper:
    n_waveshapers = %n_waveshapers
    control_embedding_size = %control_embedding_size
    shaping_fn_hidden_size = 8

# ==============
# ProcessorGroup
# ==============

ProcessorGroup.dag = [
  (@NEWTHarmonic(),
    ['f0_hz']),
  (@NEWTWaveshaper(),
    ['newt_harmonic/signal', 'control_embedding']),
  (@synths.FilteredNoise(),
    ['noise_magnitudes']),
  (@processors.Add(),
    ['filtered_noise/signal', 'newt_waveshaper/signal']),
  (@effects.Reverb(),
    ['add/signal']),
]

# Reverb
Reverb:
    name = 'reverb'
    reverb_length = 48000
    trainable = True

train_util.train.model_specific_summary_fn = @summarize_newt